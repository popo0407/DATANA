# 振り返り (Retrospective)

## 1. 実施内容の概要

「魔神」プロンプトのロジックを AWS サーバーレスアーキテクチャへ完全に移植しました。
単一の HTML プロンプトから、スケーラブルで堅牢なエンタープライズ向けシステムへと進化させました。

## 2. 憲章遵守の確認

- **分析と計画**: 最初にフェーズ分けを行い、ユーザーと合意形成を行いました。
- **リスクベース**: コアロジック（Processor）のデータクレンジングと AI 連携を最優先で設計しました。
- **技術的負債の抑制**: CloudFormation による IaC 化、React コンポーネントの共通化（ChartCard）を行いました。
- **日本語対応**: すべてのドキュメントと UI を日本語で提供しました。

## 3. 発生した問題と対策

- **問題**: Excel/VBA からの利用において WebSocket が障壁となる可能性。
- **原因**: 当初のリアルタイム性重視の設計。
- **対策**: REST API + ポーリング方式に変更し、汎用性を高めました。
- **改善**: ユーザーからのフィードバックに基づき、「成功コードパターン（Reference Architecture）」の設計思想（70/30 レポート比率、プロフェッショナルな CSS、高度な HTML エクスポート）を全面的に採用し、出力品質を大幅に向上させました。
- **問題**: ファイルアップロード後の API リクエストが 404 Not Found で失敗する。
- **原因**: API Gateway (HTTP API) において `$default` ステージが明示的に定義・デプロイされていなかったため、エンドポイントが有効になっていなかった。また、フロントエンドが S3 の結果ファイルを直接取得しようとしていたが、バケットが非公開設定（Public Access Block）であるため CORS や権限エラーが発生する設計になっていた。
- **対策**: `infra/api-stack.yml` に `AWS::ApiGatewayV2::Stage` ($default) を追加し、自動デプロイを有効化した。また、`backend/src/status.py` で分析結果ファイル（JSON）への Presigned URL を発行してフロントエンドに返すように修正し、フロントエンド側もその URL を使用するように変更した。
- **教訓**: HTTP API を CloudFormation で構築する際は、ステージの定義とデプロイ設定を忘れないこと。また、セキュリティを考慮した非公開バケットへのアクセスは、常に Presigned URL を介する設計を徹底すること。

- **問題**: ファイルアップロード後、分析ジョブが `PENDING` のまま進まない。
- **原因**:
  1. `ProcessorFunction` (Lambda) に `pandas` ライブラリがインストールされておらず、インポートエラーで起動に失敗していた。
  2. S3 バケットへのファイルアップロードをトリガーに Lambda を起動する設定（S3 Bucket Notification）が欠落していた。
- **対策**:
  1. `infra/api-stack.yml` に AWS 管理の `AWSSDKPandas-Python312` レイヤーを追加した。
  2. `scripts/deploy-infra.ps1` に、デプロイ後に `aws s3api put-bucket-notification-configuration` を実行して S3 トリガーを自動設定する処理を追加した。
- **教訓**: 外部ライブラリを使用する Lambda 関数には適切な Layer を設定すること。また、S3 トリガーのように循環参照が発生しやすい設定は、デプロイスクリプト等で補完する運用を検討すること。

- **問題**: 「ANALYZING DATA..」が終わらず、S3 へのアクセスで 301 エラーやネットワークエラーが発生する。
- **原因**:
  1. フロントエンドのビルド済みファイル（`dist`）に、開発時のプレースホルダー URL（`your-data-bucket`）がハードコードされたままデプロイされていた。
  2. バックエンド（`processor.py`）で AI が生成した JSON をパースする際、AI が出力に含めた制御文字（改行など）によって `json.loads` が失敗し、ジョブが `FAILED` になっていた。
- **対策**:
  1. フロントエンドを最新のソースコード（バックエンドから返される Presigned URL を使用するロジック）で再ビルドし、デプロイした。
  2. `processor.py` の `json.loads` に `strict=False` オプションを追加し、AI 生成コンテンツのパースを堅牢にした。
- **教訓**: デプロイ前には必ず最新のソースコードでビルドを行うこと。また、AI が生成する非構造化データ（JSON）をパースする際は、制御文字の混入を許容する設定（`strict=False`）を標準とすること。

- **問題**: デプロイスクリプト実行時に、AWS CLI からの巨大な JSON レスポンスがターミナルに表示され、ログの視認性が低下する。
- **原因**: `aws lambda update-function-code` や `aws cloudfront create-invalidation` などのコマンドが、デフォルトで詳細な実行結果を JSON 形式で標準出力するため。
- **対策**: 正常終了時には不要な出力を抑制するため、該当する AWS CLI コマンドに `> $null` を追加した。
- **教訓**: 自動化スクリプトにおいては、ユーザーが必要とする情報（進捗状況やエラーメッセージ）のみを表示し、正常系の詳細な API レスポンスは抑制することで、運用時の視認性と体験を向上させること。

- **問題**: 初期実装ではグラフ名や集計ロジックが固定されており、多様な CSV データに対応できなかった。
- **原因**: プロトタイプ段階で特定のデータ構造（売上データ等）を前提としたハードコードを行っていたため。
- **対策**: `processor.py` に「分析プラン策定フェーズ」を追加。AI が CSV のヘッダーを読み取り、最適なカラムマッピング、グラフの種類、タイトルを動的に決定するメタデータ駆動型アーキテクチャに刷新した。
- **教訓**: 汎用的な分析ツールを目指す場合、データ構造の推論を AI に委ねることで、開発者の想定を超えた多様なユースケースに対応可能になる。

- **問題**: レポートのエクスポート機能（PDF/HTML）の品質が低く、実用性に欠けていた。
- **原因**:
  1. PDF エクスポートにおいて、1 ページに収まらないコンテンツが切り捨てられていた。
  2. HTML エクスポートにおいて、KPI カードやグラフが含まれず、AI のテキストレポートのみが出力されていた。
- **対策**:
  1. PDF エクスポートロジックを修正し、コンテンツの高さに応じて自動的に改ページを行うマルチページ出力に対応した。
  2. HTML エクスポートを刷新し、Tailwind CSS と Chart.js (CDN) を活用して、ブラウザ上のダッシュボードと遜色ないビジュアル（カード、インタラクティブなグラフ、AI レポート）を 1 ファイルにパッケージングして出力するようにした。
- **教訓**: エクスポート機能はユーザーにとっての「成果物」そのものであるため、単なるデータの書き出しではなく、プレゼンテーション品質を担保する設計が必要である。

- **対策**: 「汎用セマンティック分析（Universal Semantic Analysis）」エンジンを導入。Amazon Bedrock (Claude 3.5 Sonnet) を活用し、アップロードされたデータの列定義（Metric, Dimension, Date）を動的に特定し、最適な 20 以上のグラフプランを自動生成する 3 ステップ・パイプライン（Planning -> Execution -> Insight）を構築した。さらに、製造業の生産技術者向けにプロンプトを最適化し、サイクルタイムや不良率などの現場指標を優先的に分析するロジックを組み込んだ。
- **教訓**: AI 時代のエージェント開発においては、静的なロジックではなく「メタデータ駆動型」の設計を最初から検討すべきである。AI に「何をすべきか（Plan）」を考えさせ、プログラムが「どう実行するか（Execute）」を担う分離構造により、真の汎用性が実現できる。また、ターゲットユーザー（今回は生産技術者）のドメイン知識を AI に注入することで、より実用的な洞察が得られることを確認した。

## 4. 今後の改善提案

- **Lambda Layer の自動化**: Pandas 等の重いライブラリのデプロイを CI/CD で自動化すること。
- **認証の強化**: 既存の Cognito との統合テストを実環境で行うこと。
- **大規模データ対応**: 100MB を超える CSV の場合、Lambda のメモリとタイムアウトの調整が必要。

## 5. 結論

本プロジェクトは、憲章に定められた「保守性と拡張性に優れたアプリケーション」の基準を満たして完了しました。
Reference Architecture の導入により、単一 HTML プロンプトが持っていた「美しさと洞察の深さ」を AWS 環境でも完全に再現することに成功しました。
README.md の更新および GitHub へのプッシュ準備が整っています。
