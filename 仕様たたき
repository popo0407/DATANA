AWS上で、このプロンプトと「全く同じ思考・処理」を持つシステムを構築するために必要な、**AI（LLM）側の思考ロジック**と、**システム側のデータ処理仕様**の詳細を整理しました。

AWSで再現する場合、これらは「プログラムの仕様書（要件定義書）」に相当します。

---

### 1. 「思考」のコア：AI（LLM）が実行している内容

プロンプトが指示しているAIの思考は、大きく2つのフェーズに分かれています。AWSではこれらを **Amazon Bedrock** などのLLMサービスに指示する役割になります。

#### A. 分析と提案フェーズ（思考の設計図）

* **普遍的な意味論的分析（Universal Semantic Analysis）**:
* 単に列名を読み取るだけでなく、データの「中身」をスキャンして、その列が「日付（Date）」「指標（Metric）」「属性（Dimension）」「場所（Location）」のどれに該当するかを自己判断します 。


* 
**除外判定**: IDや管理コードなど、可視化しても意味がない列を自動で特定し、分析対象から外します 。




* **グラフ構成案の作成**:
* 特定された役割に基づき、比較、推移、構成、相関、分布といった多角的な視点から、**最低20個以上**の具体的なグラフ構成案を策定します 。





#### B. 実装フェーズ（インサイト生成の思考）

* **レポートの構成比率制御**:
* 生成する分析レポートにおいて、「データの傾向分析（過去・現状）」を**約7割**、「戦略インサイト・提言（未来・アクション）」を**約3割**の比率で構成するよう思考を制御しています 。




* **個別インサイト（Micro-Insights）**:
* 全体像だけでなく、20個生成される各グラフに対して、そのグラフ特有の気づきを40文字程度の1文で生成します 。





---

### 2. 「処理」のコア：システムが実行している内容

AWSで構築する場合、以下のロジックは **AWS Lambda** などのバックエンド処理として実装する必要があります。

#### A. データクレンジングの厳格なルール

* **BOM除去と文字化け対策**:
* Excel由来のBOMを `text.replace(/^\uFEFF/, '')` で除去します 。


* 最初に `Shift_JIS` で読み込み、失敗（文字化け）した場合は `UTF-8` で再試行する再帰的ロジックを搭載します 。




* **強力な数値変換（Aggressive Number Parsing）**:
* 単なる `parseFloat` ではなく、正規表現 `/[^-0-9.]/g` を使い、カンマ、円記号、全角数字などを全て除去してから数値化します 。




* **表記揺れの吸収（Deep Column Mapping）**:
* ヘッダー名が完全に一致しなくても、「売上」「売上額」「Sales」などの表記揺れを `OR` 演算子で網羅してマッピングします 。





#### B. グラフ描画の最適化ロジック

* **高カーディナリティ処理（aggregateTopN）**:
* 店舗名など項目数が12を超える場合は、自動的に「上位10件＋その他」に集約し、グラフが潰れるのを防ぎます 。




* **キーワードの包含判定（Keyword Precedence）**:
* 「Male」が「Female」に含まれるような誤検知を防ぐため、長い単語（Female）を先に判定するロジックを厳守します 。




* **有効値による平均計算**:
* 平均値を出す際、未入力や0を分母に含めず、有効な値のみで計算します 。





---

### 3. AWSでの実装イメージ図

AWSでこの「思考」と「処理」を組み合わせる場合、以下のような構成になります。

* **データ処理（Lambda）**: 上記のクレンジング、集計、`aggregateTopN` などの「作業」を担当。
* **思考（Bedrock）**: データ構造を見て「どの20個のグラフを作るか」を決め、最終的な「戦略レポート」を書く「脳」を担当。

このシステムをAWSで起こす際の第一歩として、まずは**「AIにどのような形式でデータのメタデータを渡し、どのようなプロンプトで20個のグラフを選定させるか」**というプロンプトエンジニアリングの部分を、Amazon Bedrock用に最適化することから始めるのが良いでしょう。



AWS上でこのシステムを再現する場合、単に「HTMLを生成する」のではなく、**「データ処理エンジン」と「可視化エンジン」を分離して構成する**のが正解です。

提供されたプロンプトの思考プロセスに基づき、データを受け取ってからHTML（ダッシュボード）を表示するまでの最適な処理順序を、AWSのサービスに当てはめて解説します。

---

### 推奨される処理シーケンス

#### 1. データ受領と前処理（S3 + Lambda）

まず、アップロードされた「汚れた実務データ」を機械が扱える形に整えます。

* **エンコーディング検知:** `Shift_JIS`と`UTF-8`を判定し、BOMを除去。
* **クリーニング:** 通貨記号（¥）やカンマ（,）、全角数字を正規表現で数値変換。
* **メタデータ抽出:** カラム名、データ型、サンプル値を抽出。この情報を次の「AIへの相談」に使用します。

#### 2. AIによる分析設計図の策定（Amazon Bedrock）

プログラム（Lambda）だけでグラフの種類を決めず、ここでLLM（Claude 3.5 Sonnet等）を呼び出します。

* **入力:** 手順1で抽出した「メタデータ」を渡す。
* **思考:** 「このデータには『地域』と『売上』があるから、地図グラフとランキングが必要だ」とAIが20個のグラフ構成を決定します。
* **出力:** グラフの種類、軸の定義、集計ロジックをJSON形式で受け取ります。

#### 3. データの集計・加工（Lambda）

AIが決めた「設計図（JSON）」に従って、実際のデータ集計を行います。

* **集約処理:** `aggregateTopN`ロジックを実行。項目が多い場合は「上位10件＋その他」にまとめます。
* **計算:** 平均値、前年比、相関係数などを算出。
* **JSON化:** 可視化ライブラリ（Chart.jsなど）がそのまま読み込める形式のデータセットを作成します。

#### 4. HTML/UIの組み立てとレスポンス（API Gateway）

最後に、フロントエンドに返すHTMLを動的に生成、またはデータを流し込みます。

* **テンプレート結合:** あらかじめ用意した「ダッシュボードの骨組み（HTML/CSS/JS）」に、手順3で作成した「集計済みデータ」を埋め込みます。
* **Gemini API（またはBedrock）による考察:** 集計後の数値結果を再度AIに投げ、プロンプトにある「7割の傾向分析、3割の戦略提言」という文章を生成してHTML内に挿入します。

---

### 修正コード提示に関する補足

今後の開発において、システムの具体的な修正が必要な場合は、**「変更箇所のみ」**を提示します（例：Lambda内のクレンジングロジックのみ、Bedrockへのプロンプトのみなど）。

### AWSでの実装ポイント

この順序で組む際、以下の点に注意してください。

* **ステートレスな設計:** Lambdaは一度実行するとデータを忘れるため、手順1のクリーニング済みデータは一時的にS3やキャッシュに置くか、一連の流れを一つのワークフローとして実行します。
* **非同期処理:** 20個のグラフ計算とAIの文章生成には数秒〜数十秒かかるため、APIは一度「受付完了」を返し、フロントエンドからポーリング（確認）させるか、WebSocketを使用するとユーザー体験が向上します。
